                 from  n    params  module                                  arguments
  0                -1  1      5280  models.common.Focus                     [3, 48, 3]
  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]
  2                -1  2     65280  models.common.C3                        [96, 96, 2]
  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]
  4                -1  6    629760  models.common.C3                        [192, 192, 6]
  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]
  6                -1  6   2512896  models.common.C3                        [384, 384, 6]
  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]
  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]
  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]
 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]
 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]
 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]
 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]
 24      [17, 20, 23]  1     40410  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]
c:\Users\Acer\anaconda3\lib\site-packages\torch\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\TensorShape.cpp:3191.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 391 layers, 21072570 parameters, 21072570 gradients, 50.6 GFLOPs
Transferred 506/506 items from best.pt
Scaled weight_decay = 0.0005
[34m[1moptimizer:[39m[22m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias
[34m[1mtrain: [39m[22mScanning 'Dataset\labels\train' images and labels...1142 found, 54 missing, 0 empty, 1 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1196/1196 [00:07<00:00, 170.72it/s]
[34m[1mtrain: [39m[22mWARNING: Ignoring corrupted image and/or label Dataset\images\train\178.jpg: negative labels
[34m[1mtrain: [39m[22mWARNING: Cache directory Dataset\labels is not writeable: [WinError 183] Cannot create a file when that file already exists: 'Dataset\\labels\\train.cache.npy' -> 'Dataset\\labels\\train.cache'
[34m[1mval: [39m[22mScanning 'Dataset\labels\val' images and labels...117 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:08<00:00, 13.83it/s]
[34m[1mval: [39m[22mWARNING: Cache directory Dataset\labels is not writeable: [WinError 183] Cannot create a file when that file already exists: 'Dataset\\labels\\val.cache.npy' -> 'Dataset\\labels\\val.cache'
Plotting labels...
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to [1mruns\train\exp13
Starting training for 1 epochs...
     Epoch   gpu_mem       box       obj       cls    labels  img_size
  0%|          | 0/75 [00:00<?, ?it/s]
  0%|          | 0/75 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "d:\FRA361 ROBOTICS STUDIO IV  OPEN TOPICS\code\Vehicle-Detection-main\train.py", line 611, in <module>
    main(opt)
  File "d:\FRA361 ROBOTICS STUDIO IV  OPEN TOPICS\code\Vehicle-Detection-main\train.py", line 509, in main
    train(opt.hyp, opt, device)
  File "d:\FRA361 ROBOTICS STUDIO IV  OPEN TOPICS\code\Vehicle-Detection-main\train.py", line 311, in train
    pred = model(imgs)  # forward
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "d:\FRA361 ROBOTICS STUDIO IV  OPEN TOPICS\code\Vehicle-Detection-main\models\yolo.py", line 123, in forward
    return self.forward_once(x, profile, visualize)  # single-scale inference, train
  File "d:\FRA361 ROBOTICS STUDIO IV  OPEN TOPICS\code\Vehicle-Detection-main\models\yolo.py", line 155, in forward_once
    x = m(x)  # run
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "d:\FRA361 ROBOTICS STUDIO IV  OPEN TOPICS\code\Vehicle-Detection-main\models\common.py", line 137, in forward
    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\container.py", line 204, in forward
    input = module(input)
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "d:\FRA361 ROBOTICS STUDIO IV  OPEN TOPICS\code\Vehicle-Detection-main\models\common.py", line 103, in forward
    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "d:\FRA361 ROBOTICS STUDIO IV  OPEN TOPICS\code\Vehicle-Detection-main\models\common.py", line 45, in forward
    return self.act(self.bn(self.conv(x)))
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "c:\Users\Acer\anaconda3\lib\site-packages\torch\nn\modules\conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution